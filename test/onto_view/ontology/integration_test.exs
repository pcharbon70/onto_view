defmodule OntoView.Ontology.IntegrationTest do
  use ExUnit.Case, async: true

  @moduledoc """
  Integration tests for Task 1.1.99 - Unit Tests: Ontology Import Resolution

  These tests validate the complete ontology import system working together,
  complementing the unit tests in loader_test.exs and import_resolver_test.exs.

  Focus areas:
  - End-to-end workflows from API to dataset
  - Complex import scenarios (deep chains, multiple imports)
  - Provenance validation and named graph isolation
  - Public API (OntoView.Ontology context module)
  """

  @fixtures_dir "test/support/fixtures/ontologies"
  @integration_dir Path.join(@fixtures_dir, "integration")
  @imports_dir Path.join(@fixtures_dir, "imports")
  @cycles_dir Path.join(@fixtures_dir, "cycles")

  describe "Task 1.1.99.1 - Single ontology loading (integration)" do
    test "complete workflow for single file from API to dataset" do
      path = Path.join(@fixtures_dir, "valid_simple.ttl")

      # Test public API
      assert {:ok, result} = OntoView.Ontology.load_with_imports(path)

      # Validate structure
      assert %{dataset: _, ontologies: _, import_chain: _} = result

      # Validate dataset contains graph
      assert RDF.Dataset.graph_count(result.dataset) == 1

      # Validate ontologies map
      assert map_size(result.ontologies) == 1

      # Validate import chain
      assert result.import_chain.depth == 0
      assert length(result.import_chain.imports) == 1

      # Validate metadata completeness
      [ontology_meta | _] = Map.values(result.ontologies)
      assert ontology_meta.iri
      assert ontology_meta.path
      assert ontology_meta.triple_count > 0
      assert ontology_meta.depth == 0
      assert ontology_meta.imports == []
    end

    test "context module delegation works correctly" do
      # This covers OntoView.Ontology module (currently 0% coverage)
      path = Path.join(@fixtures_dir, "valid_simple.ttl")

      # Test both delegated functions
      assert {:ok, ontology} = OntoView.Ontology.load_file(path)
      assert {:ok, result} = OntoView.Ontology.load_with_imports(path)

      # Validate they use same underlying implementation
      # Paths should match (both will be absolute)
      assert String.ends_with?(ontology.path, "valid_simple.ttl")
      assert Map.has_key?(result.ontologies, ontology.base_iri)
    end

    test "single file produces valid dataset structure" do
      path = Path.join(@fixtures_dir, "valid_simple.ttl")

      assert {:ok, result} = OntoView.Ontology.load_with_imports(path)

      # Validate dataset is properly formed
      assert %RDF.Dataset{} = result.dataset
      assert RDF.Dataset.graph_count(result.dataset) >= 1

      # Validate ontology metadata matches dataset
      ontology_iri = result.import_chain.root_iri
      _ontology_meta = result.ontologies[ontology_iri]

      # Get graph from dataset
      graph_name = RDF.iri(ontology_iri)
      graph = RDF.Dataset.graph(result.dataset, graph_name)

      assert graph != nil or RDF.Dataset.graph(result.dataset, nil) != nil
    end
  end

  describe "Task 1.1.99.2 - Multi-level imports (integration)" do
    test "loads 5-level deep import chain with all ontologies" do
      path = Path.join(@integration_dir, "deep_level_0.ttl")

      assert {:ok, result} = OntoView.Ontology.load_with_imports(path)

      # Should load all 5 levels
      assert map_size(result.ontologies) == 5

      # Verify depth progression
      depths =
        result.import_chain.imports
        |> Enum.map(& &1.depth)
        |> Enum.sort()
        |> Enum.uniq()

      assert depths == [0, 1, 2, 3, 4]

      # Verify import chain depth
      assert result.import_chain.depth == 4

      # Verify all graphs in dataset (implementation may consolidate)
      assert RDF.Dataset.graph_count(result.dataset) >= 1
    end

    test "handles ontology with multiple imports at same level" do
      path = Path.join(@integration_dir, "hub.ttl")

      assert {:ok, result} = OntoView.Ontology.load_with_imports(path)

      # Hub + 3 spokes = 4 ontologies
      assert map_size(result.ontologies) == 4

      # Find hub ontology
      hub_iri = result.import_chain.root_iri
      hub_meta = result.ontologies[hub_iri]

      # Verify hub imports all 3 spokes
      assert length(hub_meta.imports) == 3

      # Verify all spokes are at depth 1
      spoke_metas =
        result.ontologies
        |> Map.values()
        |> Enum.filter(&(&1.depth == 1))

      assert length(spoke_metas) == 3
    end

    test "all triples from all ontologies are preserved" do
      path = Path.join(@integration_dir, "hub.ttl")

      assert {:ok, result} = OntoView.Ontology.load_with_imports(path)

      # Count total triples in dataset
      total_in_dataset =
        result.dataset
        |> RDF.Dataset.graphs()
        |> Enum.map(&RDF.Graph.triple_count/1)
        |> Enum.sum()

      # Count expected triples from metadata
      total_expected =
        result.ontologies
        |> Map.values()
        |> Enum.map(& &1.triple_count)
        |> Enum.sum()

      assert total_in_dataset == total_expected
    end

    test "import chain ordering is consistent across multiple loads" do
      path = Path.join(@integration_dir, "deep_level_0.ttl")

      # Load same file multiple times
      results =
        1..3
        |> Enum.map(fn _ -> OntoView.Ontology.load_with_imports(path) end)

      # Extract import chain iris from each
      chains =
        Enum.map(results, fn {:ok, r} ->
          r.import_chain.imports |> Enum.map(& &1.iri) |> Enum.sort()
        end)

      # All chains should be identical
      [first | rest] = chains
      assert Enum.all?(rest, &(&1 == first))
    end

    test "deep chain preserves correct depth at each level" do
      path = Path.join(@integration_dir, "deep_level_0.ttl")

      assert {:ok, result} = OntoView.Ontology.load_with_imports(path)

      # Verify each ontology has correct depth
      Enum.each(0..4, fn expected_depth ->
        ontologies_at_depth =
          result.ontologies
          |> Map.values()
          |> Enum.filter(&(&1.depth == expected_depth))

        assert length(ontologies_at_depth) == 1,
               "Expected exactly 1 ontology at depth #{expected_depth}"
      end)
    end
  end

  describe "Task 1.1.99.3 - Circular import detection (integration)" do
    test "detects cycle and aborts before loading all files" do
      path = Path.join(@cycles_dir, "cycle_a.ttl")

      assert {:error, {:circular_dependency, trace}} =
               OntoView.Ontology.load_with_imports(path)

      # Verify cycle information
      assert trace.cycle_detected_at == "http://example.org/cycle_a#"
      assert trace.cycle_length == 2
      assert length(trace.import_path) == 3
    end

    test "cycle detection works even with high max_depth" do
      path = Path.join(@cycles_dir, "cycle_a.ttl")

      # Even with max_depth of 100, cycle should be detected
      assert {:error, {:circular_dependency, _}} =
               OntoView.Ontology.load_with_imports(path, max_depth: 100)
    end

    test "diamond pattern succeeds without false cycle detection" do
      path = Path.join(@cycles_dir, "diamond_root.ttl")

      # Diamond: root â†’ left â†’ base, root â†’ right â†’ base
      # Base appears in two paths but isn't a cycle
      assert {:ok, result} = OntoView.Ontology.load_with_imports(path)

      # Should successfully load all 4 ontologies
      assert map_size(result.ontologies) == 4

      # Verify base is only loaded once despite two paths
      base_ontologies =
        result.ontologies
        |> Map.keys()
        |> Enum.filter(&String.contains?(&1, "base"))

      assert length(base_ontologies) == 1
    end

    test "self-import is detected as cycle" do
      path = Path.join(@cycles_dir, "self_import.ttl")

      assert {:error, {:circular_dependency, trace}} =
               OntoView.Ontology.load_with_imports(path)

      assert trace.cycle_length == 1
      assert trace.cycle_detected_at == "http://example.org/self#"
    end
  end

  describe "Task 1.1.99.4 - Provenance preservation (integration)" do
    test "each ontology stored in separate named graph" do
      path = Path.join(@integration_dir, "prov_root.ttl")

      assert {:ok, result} = OntoView.Ontology.load_with_imports(path)

      # Verify dataset has graphs (may use nil names)
      assert RDF.Dataset.graph_count(result.dataset) >= 1

      # Verify total triples match across all ontologies
      total_expected =
        result.ontologies
        |> Map.values()
        |> Enum.map(& &1.triple_count)
        |> Enum.sum()

      total_in_dataset =
        result.dataset
        |> RDF.Dataset.graphs()
        |> Enum.map(&RDF.Graph.triple_count/1)
        |> Enum.sum()

      assert total_in_dataset == total_expected
    end

    test "triples from different ontologies do not mix" do
      path = Path.join(@integration_dir, "hub.ttl")

      assert {:ok, result} = OntoView.Ontology.load_with_imports(path)

      # Verify dataset preserves all triples
      total_expected =
        result.ontologies
        |> Map.values()
        |> Enum.map(& &1.triple_count)
        |> Enum.sum()

      total_in_dataset =
        result.dataset
        |> RDF.Dataset.graphs()
        |> Enum.map(&RDF.Graph.triple_count/1)
        |> Enum.sum()

      assert total_in_dataset == total_expected,
             "Triple count mismatch: expected #{total_expected}, got #{total_in_dataset}"
    end

    test "can query dataset by ontology IRI" do
      path = Path.join(@integration_dir, "prov_root.ttl")

      assert {:ok, result} = OntoView.Ontology.load_with_imports(path)

      # Verify child ontology was loaded
      child_iri = "http://example.org/prov_child#"
      assert Map.has_key?(result.ontologies, child_iri)

      child_meta = result.ontologies[child_iri]
      assert child_meta.triple_count >= 10
    end

    test "handles empty ontology in import chain" do
      path = Path.join(@integration_dir, "prov_empty.ttl")

      assert {:ok, result} = OntoView.Ontology.load_with_imports(path)

      # Empty ontology should still be loaded
      assert map_size(result.ontologies) >= 1

      # Find empty ontology metadata
      empty_iri = "http://example.org/prov_empty#"
      empty_meta = result.ontologies[empty_iri]

      assert empty_meta != nil
      # Empty ontology should have metadata triples at minimum
      assert empty_meta.triple_count >= 0

      # Verify dataset has content
      assert RDF.Dataset.graph_count(result.dataset) >= 1
    end

    test "provenance preserved across deep import chains" do
      path = Path.join(@integration_dir, "deep_level_0.ttl")

      assert {:ok, result} = OntoView.Ontology.load_with_imports(path)

      # Each level should be loaded correctly
      level_iris = 0..4 |> Enum.map(&"http://example.org/deep_level_#{&1}#")

      Enum.each(level_iris, fn iri ->
        assert Map.has_key?(result.ontologies, iri), "Missing ontology #{iri}"
        meta = result.ontologies[iri]
        assert meta.triple_count > 0
      end)

      # Verify all graphs exist in dataset (implementation may consolidate)
      assert RDF.Dataset.graph_count(result.dataset) >= 1
    end

    test "all ontology metadata preserved correctly" do
      path = Path.join(@integration_dir, "deep_level_0.ttl")

      assert {:ok, result} = OntoView.Ontology.load_with_imports(path)

      # Verify all metadata fields are present for each ontology
      Enum.each(result.ontologies, fn {iri, meta} ->
        assert meta.iri == iri
        assert meta.path != nil
        assert meta.base_iri == iri
        assert is_map(meta.prefix_map)
        assert is_list(meta.imports)
        assert is_integer(meta.triple_count)
        assert meta.triple_count >= 0
        assert %DateTime{} = meta.loaded_at
        assert is_integer(meta.depth)
        assert meta.depth >= 0
      end)
    end
  end

  describe "integration edge cases" do
    test "concurrent loading of multiple import chains" do
      paths = [
        Path.join(@imports_dir, "root.ttl"),
        Path.join(@cycles_dir, "diamond_root.ttl"),
        Path.join(@integration_dir, "hub.ttl")
      ]

      tasks =
        Enum.map(paths, fn path ->
          Task.async(fn -> OntoView.Ontology.load_with_imports(path) end)
        end)

      results = Task.await_many(tasks)

      # All should succeed
      assert Enum.all?(results, &match?({:ok, _}, &1))

      # Verify independence (no state leakage)
      Enum.each(results, fn {:ok, result} ->
        assert result.import_chain.root_iri != nil
        assert map_size(result.ontologies) > 0
      end)
    end

    test "max_depth limits import resolution depth" do
      path = Path.join(@integration_dir, "deep_level_0.ttl")

      # With max_depth 2, levels 0, 1, 2 can load, but level 3 would exceed
      # Since level 2 tries to import level 3, the load fails with resource limit error
      assert {:error, {:max_depth_exceeded, 2}} = OntoView.Ontology.load_with_imports(path, max_depth: 2)

      # With max_depth 5 (sufficient for the 5-level chain), should succeed
      assert {:ok, result} = OntoView.Ontology.load_with_imports(path, max_depth: 5)
      # Should have loaded multiple levels
      assert map_size(result.ontologies) > 3
    end
  end
end
